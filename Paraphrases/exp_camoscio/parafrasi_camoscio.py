# -*- coding: utf-8 -*-
"""parafrasi_camoscio.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bWWn2bXw9LfwOvmPzpiYOnfv8V-o12O5
"""
import json
import numpy as np
from numpy import random
import requests
import torch
import sys

from peft import PeftModel
from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig


# If there's a GPU available...
if torch.cuda.is_available():

    # Tell PyTorch to use the GPU.
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

#dataset_path = "/content/gdrive/MyDrive/Teaching/22_23/Jacopo/test.json"
#dataset_path = "test_encode_latin1.json"
#dataset_path = "prova.json"
dataset_path = sys.argv[1]

"""Camoscio 7B (https://github.com/teelinsan/camoscio)

"""

#!pip install bitsandbytes
#!pip install -q datasets loralib sentencepiece
#!pip install -q git+https://github.com/zphang/transformers@c3dc391
#!pip install -q git+https://github.com/huggingface/peft.git


tokenizer = LlamaTokenizer.from_pretrained("decapoda-research/llama-7b-hf")
model = LlamaForCausalLM.from_pretrained(
    "decapoda-research/llama-7b-hf",
    load_in_8bit=True,
    device_map="auto",
)
model = PeftModel.from_pretrained(model, "teelinsan/camoscio-7b-llama")

dataset_file = open(dataset_path)
dataset = json.load(dataset_file, encoding='latin-1')
dataset_file.close()


statements = {}
for article in dataset:
  statements[article["id"]] = article["statement"]

#print(statements)


def generate_prompt(instruction, input=None):
    if input:
        return f"""Di seguito è riportata un'istruzione che descrive un task, insieme ad un input che fornisce un contesto più ampio. Scrivete una risposta che completi adeguatamente la richiesta.

        ### Istruzione:
        {instruction}

        ### Input:
        {input}

        ### Risposta:"""
    else:
        return f"""Di seguito è riportata un'istruzione che descrive un task. Scrivete una risposta che completi adeguatamente la richiesta.

    ### Istruzione: 
    {instruction}

    ### Risposta:"""

generation_config = GenerationConfig(
        temperature=0.2,
        top_p=0.75,
        num_beams=4,
)

def evaluate(instruction, input=None):
    prompt = generate_prompt(instruction, input)
    inputs = tokenizer(prompt, return_tensors="pt")
    input_ids = inputs["input_ids"].cuda()
    generation_output = model.generate(
        input_ids=input_ids,
        generation_config=generation_config,
        return_dict_in_generate=True,
        output_scores=True,
        max_new_tokens=256
    )
    for s in generation_output.sequences:
        output = tokenizer.decode(s)
        output_tokens = output.split("### Risposta:")[1].strip()
        #print(output_tokens)
        return output_tokens
#       print("Risposta:", output.split("### Risposta:")[1].strip())

#evaluate(input("Istruzione: questo task serve a riscrivere in stili diversi delle affermazioni dei politici. Devi generare delle parafrasi del testo in input come se le informazioni in input forssero dette da altre persone. Non devi cambiare il significato dell' affermazione, ma presentarla in maniera divers. Puoi aggiungere esclamazioni, opinioni personali, o addirittura delle riflessioni, ma non dati o numeri. Input: 'Abbiamo perso centomila posti di lavoro in un mese'"))
#evaluate(input("Istruzione: scrivi una parafrasi Input: Abbiamo perso centomila posti di lavoro in un mese"))
#evaluate("Istruzione: Scrivi una parafrasi di questo messaggio, come se il testo fosse scritto da un quotidiano liberal Input: Abbiamo perso centomila posti di lavoro in un mese")

def camoscio_paraphase_liberal(input_string):
  #text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio da una prospettiva liberal Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))
  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio in terza persona da una prospettiva liberal Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))

  #print(text_string)

  return text_string

def camoscio_paraphase_conservative(input_string):
  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio da una prospettiva conservatrice Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))
  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio in terza persona da una prospettiva conservatrice Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))

  #print(text_string)

  return text_string

def camoscio_paraphase_populits(input_string):
#  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio da una prospettiva populista Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))
  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio in terza persona da una prospettiva populista Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))

  #print(text_string)
  return text_string

def camoscio_paraphase(input_string):
#  text_string = evaluate("Istruzione: Scrivi una parafrasi di questo messaggio da una prospettiva populista Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))
  text_string = evaluate("Istruzione: Genera 5 parafrasi diverse per questo messaggio Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))
#  text_string = evaluate("Istruzione: Genera una parafrasi per questo messaggio Input: " + str(input_string).replace('\"', "").replace("«","").replace("»", ""))

  #print(text_string)
  return text_string

# genera parafrasi
risultati = []
counter = 0
for key, statement in statements.items():
    counter +=1
    print("Lavoro su statement " + str(counter))

    #lib_paraf = camoscio_paraphase_liberal(statement)
    #cons_paraf = camoscio_paraphase_conservative(statement)
    #pop_paraf = camoscio_paraphase_populits(statement)

    paraf = camoscio_paraphase(statement)
    paraph_sentences = tuple(paraf.split("\n"))
  
    if len(paraph_sentences) == 5 :

        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": paraph_sentences[0],
        "para2": paraph_sentences[1],
        "para3": paraph_sentences[2],
        "para4": paraph_sentences[3],
        "para5": paraph_sentences[4]
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

    elif len(paraph_sentences) == 4:
        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": paraph_sentences[0],
        "para2": paraph_sentences[1],
        "para3": paraph_sentences[2],
        "para4": paraph_sentences[3],
        "para5": "failed"
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

    elif len(paraph_sentences) == 3:
        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": paraph_sentences[0],
        "para2": paraph_sentences[1],
        "para3": paraph_sentences[2],
        "para4": "failed",
        "para5": "failed"
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

    elif len(paraph_sentences) == 2:
        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": paraph_sentences[0],
        "para2": paraph_sentences[1],
        "para3": "failed",
        "para4": "failed",
        "para5": "failed"
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

    elif len(paraph_sentences) == 1:
        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": paraph_sentences[0],
        "para2": "failed",
        "para3": "failed",
        "para4": "failed",
        "para5": "failed"
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

    else:
        combined_object = {
        "id" : key,
        "original" : statement,
        "para1": "failed",
        "para2": "failed",
        "para3": "failed",
        "para4": "failed",
        "para5": "failed"
  #      "paraphrasis_cons": cons_paraf,
  #      "paraphrasis_populist": pop_paraf
        }
        risultati.append(combined_object)

filename = "parafrasi_camoscio_5frasi" + sys.argv[1].split("/")[-1]
with open(filename, "w") as F:
    json.dump(risultati, F, indent=2, ensure_ascii=False)

